{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import cv2 # cv2 for reading and processing the images\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Keras libraries\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.optimizers import Adam\n",
    "# other libraries\n",
    "import gc\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"D:/DS/Mala_Deep_Transfer/cell_images/cell_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 112\n",
    "img_width = 112\n",
    "img_channels = 3\n",
    "np_random_seed = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_images(data_dir, image_dims = (56,56), num_of_imgs = None, convert_to_categorical = True):\n",
    "    \"\"\"\n",
    "    Function to read the images from the given directory and returns Numpy array of X, y and array of labels (names of the directory)\n",
    "    \n",
    "    The function reads from the given directory, it considers each immidiate sub-directory as a lable\n",
    "    \n",
    "    Parameters: \n",
    "    data_dir (String): Path to the directory\n",
    "    image_dims (tuple): Dimensions of the image (length, bredth). \n",
    "    num_of_imgs (int): Total number of images to be loaded, if None all the images are loaded. Equal amount of images from each sub-directory are loaded. eg: If input is 30 and there are three subdirectories then 10 images from each directory are loaded\n",
    "    convert_to_categorical (boolean): If true then y is converted to one hot vector else a single np array of series of number for each lable starting with 0\n",
    "  \n",
    "    Returns: \n",
    "    int: Description of return value \n",
    "  \n",
    "    \"\"\"\n",
    "    # initialize empty python arrays for X and y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    num_of_img_per_class = 0\n",
    "    labels = [ name for name in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, name)) ]\n",
    "    if num_of_imgs is not None:\n",
    "        num_of_img_per_class = int(round(num_of_imgs/len(labels)))\n",
    "        \n",
    "    print('num_of_img_per_class : '+str(num_of_img_per_class if num_of_img_per_class > 0 else 'All' ))\n",
    "    \n",
    "    lable_count = 0\n",
    "    #importing the Parasitized images\n",
    "    for label in labels:\n",
    "        size = 0\n",
    "        print('Importing lable : '+str(label))\n",
    "        for imgpath in os.listdir(data_dir+'/'+label):\n",
    "            try:\n",
    "                X.append(cv2.resize(cv2.imread(data_dir+'/'+label+'/'+imgpath, cv2.IMREAD_COLOR)\n",
    "                                    , image_dims, interpolation=cv2.INTER_CUBIC))\n",
    "                y.append(lable_count)\n",
    "            except BaseException as err:\n",
    "                print('Error readding file :\"'+label+'/'+imgpath+'\", '+str(err))\n",
    "            \n",
    "            size += 1\n",
    "            \n",
    "            if num_of_img_per_class == size :\n",
    "                break\n",
    "        print('Imported lable : '+str(label))\n",
    "        lable_count =+ 1\n",
    "    \n",
    "    # converting the python array into Numpy array\n",
    "    X_np = np.array(X)\n",
    "    y_temp = np.array(y)\n",
    "    \n",
    "    # converting the y variables to categorical\n",
    "    if(convert_to_categorical) :\n",
    "        y_np = to_categorical(y_temp,len(labels))\n",
    "        del y_temp\n",
    "        gc.collect()\n",
    "    else:\n",
    "        y_np = y_temp\n",
    "    print ('converted to np arrays')\n",
    "    \n",
    "    # deleting the python arrays as they are no longer required and it would reduce the memory\n",
    "    del X\n",
    "    del y\n",
    "    gc.collect()\n",
    "    print ('deleted temp arrays')\n",
    "\n",
    "    # Normalizing and converting the data into float\n",
    "    X_np.astype('float32')/255.0\n",
    "    print ('data normalized')\n",
    "\n",
    "    return X_np, y_np, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(np_random_seed)\n",
    "X, y, lables = read_and_process_images('D://DS//Mala_Deep_Transfer//cell_images//cell_images', image_dims=(img_height,img_width))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,shuffle = True,stratify = y)\n",
    "print('X_train Shape : '+str(X_train.shape))\n",
    "print('X_test Shape : '+str(X_test.shape))\n",
    "print('y_train Shape : '+str(y_train.shape))\n",
    "print('y_test Shape : '+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(X, y, start_idx = 0,num_imgs = 10, img_per_row = 5):\n",
    "    \"\"\"\n",
    "    Displays the images from the given data X\n",
    "    \n",
    "    Parameters: \n",
    "    X (numpy.array) : Numpy array of images\n",
    "    start_idx(int) : Index from where we start viewing the, make sure that the number doesnot exceed the length of the X_train\n",
    "    num_imgs (int) : Total number of images that have to be displayed\n",
    "    img_per_row (int) : Number of images that have to be displayed per row\n",
    "    \"\"\"\n",
    "    num_rows = int(num_imgs/img_per_row) + 1\n",
    "    plt.figure(figsize = (18,4 * num_rows))\n",
    "    for i in range(1,num_imgs+1):\n",
    "        plt.subplot(num_rows,img_per_row,i)\n",
    "        plt.title(str(lables[np.argmax(y[start_idx])]))\n",
    "        plt.imshow(X_train[start_idx])\n",
    "        start_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(X_test, y_test,100, 20,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the base resnet50 model trained on imagenet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, \n",
    "                      weights='imagenet', \n",
    "                      input_shape=(img_height, img_width, img_channels))\n",
    "base_model.trainable = False #Tells that all the weights are to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= models.Sequential()           #Creating the sequntial model\n",
    "model.add(base_model)                #Adding the imagenet model\n",
    "model.add(Flatten())                                #\n",
    "model.add(Dense(512,activation=\"relu\"))             #\n",
    "model.add(Dropout(0.2))                             #\n",
    "model.add(Dense(len(lables),activation=\"softmax\"))  #\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(4e-5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = model.fit(X_train,y_train,batch_size=32, epochs= 5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs = his.history['acc']\n",
    "train_losses = his.history['loss']\n",
    "val_accs = his.history['val_acc']\n",
    "val_losses = his.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_accs)+1)\n",
    "\n",
    "plt.plot(epochs,train_accs, 'b', label='Train Accuracy')\n",
    "plt.plot(epochs,val_accs, 'r', label='Validation Accuracy')\n",
    "plt.title('Train and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,train_losses, 'b', label='Train Loss')\n",
    "plt.plot(epochs,val_losses, 'r', label='Validation Loss')\n",
    "plt.title('Train and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
